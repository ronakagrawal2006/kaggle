{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATE = True\n",
    "\n",
    "MAX_ROUNDS = 500\n",
    "EARLY_STOP = 50\n",
    "OPT_ROUNDS = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "        'ip'            : 'uint32',\n",
    "        'app'           : 'uint16',\n",
    "        'device'        : 'uint16',\n",
    "        'os'            : 'uint16',\n",
    "        'channel'       : 'uint16',\n",
    "        'is_attributed' : 'uint8',\n",
    "        'click_id'      : 'uint32'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load train...\n"
     ]
    }
   ],
   "source": [
    "print('load train...')\n",
    "train_cols = ['ip','app','device','os', 'channel', 'click_time', 'is_attributed']\n",
    "train_df = pd.read_csv(path+\"train.csv\", skiprows=range(1,109903891), nrows=750000,dtype=dtypes, usecols=train_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data prep...\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "len_train = len(train_df)\n",
    "print(len_train)\n",
    "gc.collect()\n",
    "\n",
    "print('data prep...')\n",
    "\n",
    "most_freq_hours_in_test_data = [4, 5, 9, 10, 13, 14]\n",
    "least_freq_hours_in_test_data = [6, 11, 15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data( df ):\n",
    "    \n",
    "    df['hour'] = pd.to_datetime(df.click_time).dt.hour.astype('uint8')\n",
    "    df['day'] = pd.to_datetime(df.click_time).dt.day.astype('uint8')\n",
    "    df.drop(['click_time'], axis=1, inplace=True)\n",
    "    gc.collect()\n",
    "    \n",
    "    df['in_test_hh'] = (   3 \n",
    "                         - 2*df['hour'].isin(  most_freq_hours_in_test_data ) \n",
    "                         - 1*df['hour'].isin( least_freq_hours_in_test_data ) ).astype('uint8')\n",
    "    print( df.info() )\n",
    "\n",
    "#     print('group by : ip_day_test_hh')\n",
    "#     gp = df[['ip', 'day', 'in_test_hh', 'channel']].groupby(by=['ip', 'day',\n",
    "#              'in_test_hh'])[['channel']].count().reset_index().rename(index=str, \n",
    "#              columns={'channel': 'nip_day_test_hh'})\n",
    "#     df = df.merge(gp, on=['ip','day','in_test_hh'], how='left')\n",
    "#     del gp\n",
    "#     df.drop(['in_test_hh'], axis=1, inplace=True)\n",
    "#     print( \"nip_day_test_hh max value = \", df.nip_day_test_hh.max() )\n",
    "#     df['nip_day_test_hh'] = df['nip_day_test_hh'].astype('uint32')\n",
    "#     gc.collect()\n",
    "#     print( df.info() )\n",
    "\n",
    "#     print('group by : ip_day_hh')\n",
    "#     gp = df[['ip', 'day', 'hour', 'channel']].groupby(by=['ip', 'day', \n",
    "#              'hour'])[['channel']].count().reset_index().rename(index=str, \n",
    "#              columns={'channel': 'nip_day_hh'})\n",
    "#     df = df.merge(gp, on=['ip','day','hour'], how='left')\n",
    "#     del gp\n",
    "#     print( \"nip_day_hh max value = \", df.nip_day_hh.max() )\n",
    "#     df['nip_day_hh'] = df['nip_day_hh'].astype('uint16')\n",
    "#     gc.collect()\n",
    "#     print( df.info() )\n",
    "\n",
    "#     print('group by : ip_hh_os')\n",
    "#     gp = df[['ip', 'os', 'hour', 'channel']].groupby(by=['ip', 'os', \n",
    "#              'hour'])[['channel']].count().reset_index().rename(index=str, \n",
    "#              columns={'channel': 'nip_hh_os'})\n",
    "#     df = df.merge(gp, on=['ip','os','hour'], how='left')\n",
    "#     del gp\n",
    "#     print( \"nip_hh_os max value = \", df.nip_hh_os.max() )\n",
    "#     df['nip_hh_os'] = df['nip_hh_os'].astype('uint16')\n",
    "#     gc.collect()\n",
    "#     print( df.info() )\n",
    "\n",
    "#     print('group by : ip_hh_app')\n",
    "#     gp = df[['ip', 'app', 'hour', 'channel']].groupby(by=['ip', 'app', \n",
    "#              'hour'])[['channel']].count().reset_index().rename(index=str, \n",
    "#              columns={'channel': 'nip_hh_app'})\n",
    "#     df = df.merge(gp, on=['ip','app','hour'], how='left')\n",
    "#     del gp\n",
    "#     print( \"nip_hh_app max value = \", df.nip_hh_app.max() )\n",
    "#     df['nip_hh_app'] = df['nip_hh_app'].astype('uint16')\n",
    "#     gc.collect()\n",
    "#     print( df.info() )\n",
    "\n",
    "#     print('group by : ip_hh_dev')\n",
    "#     gp = df[['ip', 'device', 'hour', 'channel']].groupby(by=['ip', 'device', \n",
    "#              'hour'])[['channel']].count().reset_index().rename(index=str, \n",
    "#              columns={'channel': 'nip_hh_dev'})\n",
    "#     df = df.merge(gp, on=['ip','device','hour'], how='left')\n",
    "#     del gp\n",
    "#     print( \"nip_hh_dev max value = \", df.nip_hh_dev.max() )\n",
    "#     df['nip_hh_dev'] = df['nip_hh_dev'].astype('uint32')\n",
    "#     gc.collect()\n",
    "#     print( df.info() )\n",
    "\n",
    "    df.drop( ['ip','day'], axis=1, inplace=True )\n",
    "    gc.collect()\n",
    "    print( df.info() )\n",
    "    \n",
    "    return( df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train info before: \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 750000 entries, 0 to 749999\n",
      "Data columns (total 7 columns):\n",
      "ip               750000 non-null uint32\n",
      "app              750000 non-null uint16\n",
      "device           750000 non-null uint16\n",
      "os               750000 non-null uint16\n",
      "channel          750000 non-null uint16\n",
      "click_time       750000 non-null object\n",
      "is_attributed    750000 non-null uint8\n",
      "dtypes: object(1), uint16(4), uint32(1), uint8(1)\n",
      "memory usage: 15.0+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 750000 entries, 0 to 749999\n",
      "Data columns (total 9 columns):\n",
      "ip               750000 non-null uint32\n",
      "app              750000 non-null uint16\n",
      "device           750000 non-null uint16\n",
      "os               750000 non-null uint16\n",
      "channel          750000 non-null uint16\n",
      "is_attributed    750000 non-null uint8\n",
      "hour             750000 non-null uint8\n",
      "day              750000 non-null uint8\n",
      "in_test_hh       750000 non-null uint8\n",
      "dtypes: uint16(4), uint32(1), uint8(4)\n",
      "memory usage: 11.4 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 750000 entries, 0 to 749999\n",
      "Data columns (total 7 columns):\n",
      "app              750000 non-null uint16\n",
      "device           750000 non-null uint16\n",
      "os               750000 non-null uint16\n",
      "channel          750000 non-null uint16\n",
      "is_attributed    750000 non-null uint8\n",
      "hour             750000 non-null uint8\n",
      "in_test_hh       750000 non-null uint8\n",
      "dtypes: uint16(4), uint8(3)\n",
      "memory usage: 7.9 MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train info after: \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 750000 entries, 0 to 749999\n",
      "Data columns (total 7 columns):\n",
      "app              750000 non-null uint16\n",
      "device           750000 non-null uint16\n",
      "os               750000 non-null uint16\n",
      "channel          750000 non-null uint16\n",
      "is_attributed    750000 non-null uint8\n",
      "hour             750000 non-null uint8\n",
      "in_test_hh       750000 non-null uint8\n",
      "dtypes: uint16(4), uint8(3)\n",
      "memory usage: 7.9 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print( \"Train info before: \")\n",
    "print( train_df.info() )\n",
    "train_df = prep_data( train_df )\n",
    "gc.collect()\n",
    "print( \"Train info after: \")\n",
    "print( train_df.info() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vars and data type: \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 750000 entries, 0 to 749999\n",
      "Data columns (total 7 columns):\n",
      "app              750000 non-null uint16\n",
      "device           750000 non-null uint16\n",
      "os               750000 non-null uint16\n",
      "channel          750000 non-null uint16\n",
      "is_attributed    750000 non-null uint8\n",
      "hour             750000 non-null uint8\n",
      "in_test_hh       750000 non-null uint8\n",
      "dtypes: uint16(4), uint8(3)\n",
      "memory usage: 7.9 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"vars and data type: \")\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = 'auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric':metrics,\n",
    "        'learning_rate': 0.1,\n",
    "        'num_leaves': 7,  # we should let it be smaller than 2^(max_depth)\n",
    "        'max_depth': 4,  # -1 means no limit\n",
    "        'min_child_samples': 100,  # Minimum number of data need in a child(min_data_in_leaf)\n",
    "        'max_bin': 100,  # Number of bucketed bin for feature values\n",
    "        'subsample': 0.7,  # Subsample ratio of the training instance.\n",
    "        'subsample_freq': 1,  # frequence of subsample, <=0 means no enable\n",
    "        'colsample_bytree': 0.7,  # Subsample ratio of columns when constructing each tree.\n",
    "        'min_child_weight': 0,  # Minimum sum of instance weight(hessian) needed in a child(leaf)\n",
    "        'min_split_gain': 0,  # lambda_l1, lambda_l2 and min_gain_to_split to regularization\n",
    "        'nthread': 4,\n",
    "        'verbose': 0,\n",
    "        'scale_pos_weight':99.7, # because training data is extremely unbalanced \n",
    "        'metric':metrics\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'is_attributed'\n",
    "predictors = ['app','device','os', 'channel', 'hour']#,'nip_day_test_hh', 'nip_day_hh',\n",
    "#               'nip_hh_os', 'nip_hh_app', 'nip_hh_dev'\n",
    "categorical = ['app', 'device', 'os', 'channel', 'hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        app  device  os  channel  is_attributed  hour  in_test_hh\n",
      "425729   12       1  19      259              0    12           3\n",
      "447007    9       1  17      334              0    12           3\n",
      "25761     3       1  13      280              0    12           3\n",
      "471245   27       1   8      153              0    12           3\n",
      "269745   18       1   6      107              0    12           3\n"
     ]
    }
   ],
   "source": [
    "print(train_df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 643031 entries, 333285 to 686020\n",
      "Data columns (total 7 columns):\n",
      "app              643031 non-null uint16\n",
      "device           643031 non-null uint16\n",
      "os               643031 non-null uint16\n",
      "channel          643031 non-null uint16\n",
      "is_attributed    643031 non-null uint8\n",
      "hour             643031 non-null uint8\n",
      "in_test_hh       643031 non-null uint8\n",
      "dtypes: uint16(4), uint8(3)\n",
      "memory usage: 11.7 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 33844 entries, 436733 to 187041\n",
      "Data columns (total 7 columns):\n",
      "app              33844 non-null uint16\n",
      "device           33844 non-null uint16\n",
      "os               33844 non-null uint16\n",
      "channel          33844 non-null uint16\n",
      "is_attributed    33844 non-null uint8\n",
      "hour             33844 non-null uint8\n",
      "in_test_hh       33844 non-null uint8\n",
      "dtypes: uint16(4), uint8(3)\n",
      "memory usage: 628.0 KB\n",
      "None\n",
      "train size:  643031\n",
      "valid size:  33844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aronak/miniconda3/envs/ml_3_6/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "484"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aronak/miniconda3/envs/ml_3_6/lib/python3.5/site-packages/lightgbm/basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/Users/aronak/miniconda3/envs/ml_3_6/lib/python3.5/site-packages/lightgbm/basic.py:681: UserWarning: categorical_feature in param dict is overrided.\n",
      "  warnings.warn('categorical_feature in param dict is overrided.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[10]\ttrain's auc: 0.970178\tvalid's auc: 0.967905\n",
      "[20]\ttrain's auc: 0.971495\tvalid's auc: 0.970504\n",
      "[30]\ttrain's auc: 0.974873\tvalid's auc: 0.974847\n",
      "[40]\ttrain's auc: 0.977151\tvalid's auc: 0.978299\n",
      "[50]\ttrain's auc: 0.978551\tvalid's auc: 0.980056\n",
      "[60]\ttrain's auc: 0.98015\tvalid's auc: 0.98149\n",
      "[70]\ttrain's auc: 0.981723\tvalid's auc: 0.982113\n",
      "[80]\ttrain's auc: 0.982743\tvalid's auc: 0.983076\n",
      "[90]\ttrain's auc: 0.983598\tvalid's auc: 0.983148\n",
      "[100]\ttrain's auc: 0.984212\tvalid's auc: 0.984482\n",
      "[110]\ttrain's auc: 0.984871\tvalid's auc: 0.983569\n",
      "[120]\ttrain's auc: 0.985422\tvalid's auc: 0.98426\n",
      "[130]\ttrain's auc: 0.98584\tvalid's auc: 0.984353\n",
      "[140]\ttrain's auc: 0.986293\tvalid's auc: 0.983904\n",
      "[150]\ttrain's auc: 0.98664\tvalid's auc: 0.983338\n",
      "[160]\ttrain's auc: 0.986791\tvalid's auc: 0.983605\n",
      "[170]\ttrain's auc: 0.986844\tvalid's auc: 0.98362\n",
      "Early stopping, best iteration is:\n",
      "[126]\ttrain's auc: 0.985651\tvalid's auc: 0.98498\n",
      "\n",
      "Model Report\n",
      "n_estimators :  126\n",
      "auc: 0.984979582769\n"
     ]
    }
   ],
   "source": [
    " train_df, val_df = train_test_split( train_df, train_size=.95, random_state=99, shuffle=True )\n",
    "\n",
    "print(train_df.info())\n",
    "print(val_df.info())\n",
    "\n",
    "print(\"train size: \", len(train_df))\n",
    "print(\"valid size: \", len(val_df))\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print(\"Training...\")\n",
    "\n",
    "num_boost_round=MAX_ROUNDS\n",
    "early_stopping_rounds=EARLY_STOP\n",
    "\n",
    "xgtrain = lgb.Dataset(train_df[predictors].values, label=train_df[target].values,\n",
    "                      feature_name=predictors,\n",
    "                      categorical_feature=categorical\n",
    "                      )\n",
    "del train_df\n",
    "gc.collect()\n",
    "\n",
    "xgvalid = lgb.Dataset(val_df[predictors].values, label=val_df[target].values,\n",
    "                      feature_name=predictors,\n",
    "                      categorical_feature=categorical\n",
    "                      )\n",
    "del val_df\n",
    "gc.collect()\n",
    "\n",
    "evals_results = {}\n",
    "\n",
    "bst = lgb.train(lgb_params, \n",
    "                 xgtrain, \n",
    "                 valid_sets=[xgtrain, xgvalid], \n",
    "                 valid_names=['train','valid'], \n",
    "                 evals_result=evals_results, \n",
    "                 num_boost_round=num_boost_round,\n",
    "                 early_stopping_rounds=early_stopping_rounds,\n",
    "                 verbose_eval=10, \n",
    "                 feval=None)\n",
    "\n",
    "n_estimators = bst.best_iteration\n",
    "\n",
    "print(\"\\nModel Report\")\n",
    "print(\"n_estimators : \", n_estimators)\n",
    "print(metrics+\":\", evals_results['valid'][metrics][n_estimators-1])\n",
    "\n",
    "del xgvalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
