{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read File,\n",
    "2. Prep Data for single feature\n",
    "3. Combine prep data\n",
    "4. dump to oven ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks in each feature extraction\n",
    "in : data frame\n",
    "out: processed dataframe\n",
    "\n",
    "1. add some setup of columns\n",
    "2. group by some aggregations, may be\n",
    "3. drop if no longer used\n",
    "4. gc collect\n",
    "5  write dataframe to csv\n",
    "5. return the processed data frame, and csv name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file='eda/input/train_specific_hours_sample.csv'\n",
    "# valid_file='eda/input/valid_specific_hours_sample.csv'\n",
    "valid_file=('eda/input/valid_specific_hours_sampletest_hours.csv')\n",
    "test_file='input/test_parsed.csv'\n",
    "comment=\"_valid_hr_is_test_hr\"\n",
    "overwrite=True\n",
    "file_in_progress=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_file(name):\n",
    "    global file_in_progress\n",
    "    file_in_progress=name\n",
    "def feature_file(file):\n",
    "    return str.lower(folder_path(file)+csv_name(file))\n",
    "def csv_name(file):\n",
    "    if 'csv' not in file:\n",
    "        return file+comment+'.csv' \n",
    "    return file\n",
    "def folder_path(name):\n",
    "    folder=get_folder(name)\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    return folder\n",
    "def get_folder(name):\n",
    "    global file_in_progress\n",
    "    if 'train' in file_in_progress:\n",
    "        return 'eda/features/'+'train/'\n",
    "    elif 'valid' in file_in_progress:\n",
    "        return 'eda/features/'+'valid/'\n",
    "    elif 'test' in file_in_progress:\n",
    "        return 'eda/features/'+'test/'\n",
    "    else:\n",
    "        return 'eda/features/'\n",
    "    \n",
    "def log_feature(df,name):\n",
    "    df.to_csv(feature_file(name),index=False,header=True)\n",
    "\n",
    "def skip_if_already_exists(agg_name):\n",
    "    global overwrite\n",
    "    if not overwrite:\n",
    "        if os.path.exists(feature_file(agg_name)):\n",
    "            print(feature_file(agg_name) + ' already exists')\n",
    "            df = pd.read_csv(feature_file(agg_name))\n",
    "            return df\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        if os.path.exists(feature_file(agg_name)):\n",
    "            print('deleting ',feature_file(agg_name),'...')\n",
    "            os.remove(feature_file(agg_name))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_TEST_HH='IN_TEST_HH'\n",
    "def in_test_hh(df,key=IN_TEST_HH):\n",
    "    gp = skip_if_already_exists(key)\n",
    "    if gp is not None:\n",
    "        return gp\n",
    "    else:\n",
    "        most_freq_hours_in_test_data = [4, 5, 9, 10, 13, 14]\n",
    "        least_freq_hours_in_test_data = [6, 11, 15]\n",
    "        import gc\n",
    "        gc.collect()\n",
    "        df[key] = (3 \n",
    "                - 2*df['hour'].isin(most_freq_hours_in_test_data ) \n",
    "                - 1*df['hour'].isin( least_freq_hours_in_test_data ) ).astype('uint8')\n",
    "        log_feature(df,key)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_cols( df, group_cols, agg_name, agg_type='uint32', show_max=False, show_agg=True):\n",
    "    if show_agg:\n",
    "        print( \"Aggregating by \", group_cols , '...' )\n",
    "    gp = skip_if_already_exists(agg_name) \n",
    "    if gp is None:\n",
    "        gp = df[group_cols][group_cols].groupby(group_cols).size().rename(agg_name).to_frame().reset_index()\n",
    "        log_feature(gp,agg_name)\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_FEATURES='base_features'\n",
    "def base_features(df,key=BASE_FEATURES):\n",
    "    gp=skip_if_already_exists(key)\n",
    "    if gp is None:\n",
    "        log_feature(df,key)\n",
    "        return df\n",
    "    return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "IP_DAY_TEST_HH='IP_DAY_TEST_HH'\n",
    "IP_DAY_HH='IP_DAY_HH'\n",
    "IP_OS_HH='IP_OS_HH'\n",
    "IP_APP_HH='IP_APP_HH'\n",
    "IP_APP_OS_HH='IP_APP_OS_HH'\n",
    "APP_DAY_HH='APP_DAY_HH'\n",
    "def ip_day_test(df,key = IP_DAY_TEST_HH):\n",
    "    return aggregate_cols(df, ['ip', 'day', IN_TEST_HH], key, show_max=True )\n",
    "def ip_day_hh(df,key = IP_DAY_HH):\n",
    "    return aggregate_cols( df, ['ip', 'day', 'hour'], key, 'uint16', show_max=True );\n",
    "def ip_os_hh(df,key = IP_OS_HH):\n",
    "    return aggregate_cols( df, ['ip', 'day', 'os', 'hour'], key, 'uint16', show_max=True );\n",
    "def ip_app_hh(df,key = IP_APP_HH):\n",
    "    return aggregate_cols( df, ['ip', 'day', 'app', 'hour'], key, 'uint16', show_max=True );\n",
    "def ip_app_os_hh(df,key = IP_APP_OS_HH):\n",
    "    return aggregate_cols( df, ['ip', 'day', 'app', 'os', 'hour'], key, 'uint16', show_max=True );\n",
    "def app_day_hh(df,key = APP_DAY_HH):\n",
    "    return aggregate_cols( df, ['app', 'day', 'hour'], key, 'uint16', show_max=True );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_config={\n",
    "    BASE_FEATURES :base_features,\n",
    "    IN_TEST_HH    :in_test_hh,\n",
    "    IP_DAY_TEST_HH:ip_day_test,\n",
    "    IP_DAY_HH     :ip_day_hh,\n",
    "    IP_OS_HH      : ip_os_hh,\n",
    "    IP_APP_HH     :ip_app_hh,\n",
    "    IP_APP_OS_HH  :ip_app_os_hh,\n",
    "    APP_DAY_HH    :app_day_hh,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "applicable_features=[\n",
    "    BASE_FEATURES,\n",
    "    IN_TEST_HH,  \n",
    "    IP_DAY_TEST_HH,\n",
    "    IP_DAY_HH     ,\n",
    "    IP_OS_HH      ,\n",
    "    IP_APP_HH     ,\n",
    "    IP_APP_OS_HH  ,\n",
    "    APP_DAY_HH    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(file):\n",
    "    df=pd.read_csv(file)\n",
    "    set_file(file)\n",
    "    for each_feature in applicable_features:\n",
    "        print('generating '+each_feature+'...')\n",
    "        df=feature_config[each_feature](df)\n",
    "        print(feature_file(each_feature))\n",
    "    df.to_csv(feature_file('all_features'),index=False)\n",
    "    print(feature_file('all_features'))\n",
    "    del df\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating base_features...\n",
      "deleting  eda/features/train/base_features.csv ...\n",
      "eda/features/train/base_features.csv\n",
      "generating IN_TEST_HH...\n",
      "eda/features/train/in_test_hh.csv\n",
      "generating IP_DAY_TEST_HH...\n",
      "Aggregating by  ['ip', 'day', 'IN_TEST_HH'] ...\n",
      "deleting  eda/features/train/ip_day_test_hh.csv ...\n",
      "IP_DAY_TEST_HH max value =  1117\n",
      "eda/features/train/ip_day_test_hh.csv\n",
      "generating IP_DAY_HH...\n",
      "Aggregating by  ['ip', 'day', 'hour'] ...\n",
      "deleting  eda/features/train/ip_day_hh.csv ...\n",
      "IP_DAY_HH max value =  247\n",
      "eda/features/train/ip_day_hh.csv\n",
      "generating IP_OS_HH...\n",
      "Aggregating by  ['ip', 'day', 'os', 'hour'] ...\n",
      "deleting  eda/features/train/ip_os_hh.csv ...\n",
      "IP_OS_HH max value =  59\n",
      "eda/features/train/ip_os_hh.csv\n",
      "generating IP_APP_HH...\n",
      "Aggregating by  ['ip', 'day', 'app', 'hour'] ...\n",
      "deleting  eda/features/train/ip_app_hh.csv ...\n",
      "IP_APP_HH max value =  45\n",
      "eda/features/train/ip_app_hh.csv\n",
      "generating IP_APP_OS_HH...\n",
      "Aggregating by  ['ip', 'day', 'app', 'os', 'hour'] ...\n",
      "deleting  eda/features/train/ip_app_os_hh.csv ...\n",
      "IP_APP_OS_HH max value =  15\n",
      "eda/features/train/ip_app_os_hh.csv\n",
      "generating APP_DAY_HH...\n",
      "Aggregating by  ['app', 'day', 'hour'] ...\n",
      "deleting  eda/features/train/app_day_hh.csv ...\n",
      "APP_DAY_HH max value =  4433\n",
      "eda/features/train/app_day_hh.csv\n",
      "eda/features/train/all_features.csv\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "get_features(train_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating base_features...\n",
      "eda/features/valid/base_features_valid_hr_is_test_hr.csv\n",
      "generating IN_TEST_HH...\n",
      "eda/features/valid/in_test_hh_valid_hr_is_test_hr.csv\n",
      "generating IP_DAY_TEST_HH...\n",
      "Aggregating by  ['ip', 'day', 'IN_TEST_HH'] ...\n",
      "IP_DAY_TEST_HH max value =  917\n",
      "eda/features/valid/ip_day_test_hh_valid_hr_is_test_hr.csv\n",
      "generating IP_DAY_HH...\n",
      "Aggregating by  ['ip', 'day', 'hour'] ...\n",
      "IP_DAY_HH max value =  237\n",
      "eda/features/valid/ip_day_hh_valid_hr_is_test_hr.csv\n",
      "generating IP_OS_HH...\n",
      "Aggregating by  ['ip', 'day', 'os', 'hour'] ...\n",
      "IP_OS_HH max value =  55\n",
      "eda/features/valid/ip_os_hh_valid_hr_is_test_hr.csv\n",
      "generating IP_APP_HH...\n",
      "Aggregating by  ['ip', 'day', 'app', 'hour'] ...\n",
      "IP_APP_HH max value =  41\n",
      "eda/features/valid/ip_app_hh_valid_hr_is_test_hr.csv\n",
      "generating IP_APP_OS_HH...\n",
      "Aggregating by  ['ip', 'day', 'app', 'os', 'hour'] ...\n",
      "IP_APP_OS_HH max value =  11\n",
      "eda/features/valid/ip_app_os_hh_valid_hr_is_test_hr.csv\n",
      "generating APP_DAY_HH...\n",
      "Aggregating by  ['app', 'day', 'hour'] ...\n",
      "APP_DAY_HH max value =  4750\n",
      "eda/features/valid/app_day_hh_valid_hr_is_test_hr.csv\n",
      "eda/features/valid/all_features_valid_hr_is_test_hr.csv\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "get_features(valid_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating base_features...\n",
      "deleting  eda/features/test/base_features.csv ...\n",
      "eda/features/test/base_features.csv\n",
      "generating IN_TEST_HH...\n",
      "eda/features/test/in_test_hh.csv\n",
      "generating IP_DAY_TEST_HH...\n",
      "Aggregating by  ['ip', 'day', 'IN_TEST_HH'] ...\n",
      "IP_DAY_TEST_HH max value =  182513\n",
      "eda/features/test/ip_day_test_hh.csv\n",
      "generating IP_DAY_HH...\n",
      "Aggregating by  ['ip', 'day', 'hour'] ...\n",
      "IP_DAY_HH max value =  40231\n",
      "eda/features/test/ip_day_hh.csv\n",
      "generating IP_OS_HH...\n",
      "Aggregating by  ['ip', 'day', 'os', 'hour'] ...\n",
      "IP_OS_HH max value =  8224\n",
      "eda/features/test/ip_os_hh.csv\n",
      "generating IP_APP_HH...\n",
      "Aggregating by  ['ip', 'day', 'app', 'hour'] ...\n",
      "IP_APP_HH max value =  6250\n",
      "eda/features/test/ip_app_hh.csv\n",
      "generating IP_APP_OS_HH...\n",
      "Aggregating by  ['ip', 'day', 'app', 'os', 'hour'] ...\n",
      "IP_APP_OS_HH max value =  1307\n",
      "eda/features/test/ip_app_os_hh.csv\n",
      "generating APP_DAY_HH...\n",
      "Aggregating by  ['app', 'day', 'hour'] ...\n",
      "APP_DAY_HH max value =  522993\n",
      "eda/features/test/app_day_hh.csv\n",
      "eda/features/test/all_features.csv\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "test_file='input/test_parsed.csv'\n",
    "get_features(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
