{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read File,\n",
    "2. Prep Data for single feature\n",
    "3. Combine prep data\n",
    "4. dump to oven ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks in each feature extraction\n",
    "in : data frame\n",
    "out: processed dataframe\n",
    "\n",
    "1. add some setup of columns\n",
    "2. group by some aggregations, may be\n",
    "3. drop if no longer used\n",
    "4. gc collect\n",
    "5  write dataframe to csv\n",
    "5. return the processed data frame, and csv name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file='eda/input/train_specific_hours_sample.csv'\n",
    "# valid_file='eda/input/valid_specific_hours_sample.csv'\n",
    "valid_file=('eda/input/valid_specific_hours_sampletest_hours.csv')\n",
    "test_file='input/test_parsed.csv'\n",
    "comment=\"_valid_hr_is_test_hr\"\n",
    "overwrite=True\n",
    "file_in_progress=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_file(name):\n",
    "    global file_in_progress\n",
    "    file_in_progress=name\n",
    "def feature_file(file):\n",
    "    return str.lower(folder_path(file)+csv_name(file))\n",
    "def csv_name(file):\n",
    "    if 'csv' not in file:\n",
    "        return file+comment+'.csv' \n",
    "    return file\n",
    "def folder_path(name):\n",
    "    folder=get_folder(name)\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    return folder\n",
    "def get_folder(name):\n",
    "    global file_in_progress\n",
    "    if 'train' in file_in_progress:\n",
    "        return 'eda/features/'+'train/'\n",
    "    elif 'valid' in file_in_progress:\n",
    "        return 'eda/features/'+'valid/'\n",
    "    elif 'test' in file_in_progress:\n",
    "        return 'eda/features/'+'test/'\n",
    "    else:\n",
    "        return 'eda/features/'\n",
    "    \n",
    "def log_feature(df,name,group_cols):\n",
    "    if name is 'base_features':\n",
    "        df.to_csv(feature_file(name),index=False,header=True)\n",
    "    else:\n",
    "        df[list(set().union([name],group_cols))].head()\n",
    "        df[list(set().union([name],group_cols))].to_csv(feature_file(name),index=False,header=True)\n",
    "\n",
    "def skip_if_already_exists(agg_name):\n",
    "    global overwrite\n",
    "    if not overwrite:\n",
    "        if os.path.exists(feature_file(agg_name)):\n",
    "            print(feature_file(agg_name) + ' already exists')\n",
    "            df = pd.read_csv(feature_file(agg_name))\n",
    "            return df\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        if os.path.exists(feature_file(agg_name)):\n",
    "            print('deleting ',feature_file(agg_name),'...')\n",
    "            os.remove(feature_file(agg_name))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_TEST_HH='IN_TEST_HH'\n",
    "def in_test_hh(df,key=IN_TEST_HH):\n",
    "    gp = skip_if_already_exists(key)\n",
    "    if gp is not None:\n",
    "        df[key]=gp[key]\n",
    "        return df\n",
    "    else:\n",
    "        most_freq_hours_in_test_data = [4, 5, 9, 10, 13, 14]\n",
    "        least_freq_hours_in_test_data = [6, 11, 15]\n",
    "        import gc\n",
    "        gc.collect()\n",
    "        df[key] = (3 \n",
    "                - 2*df['hour'].isin(most_freq_hours_in_test_data ) \n",
    "                - 1*df['hour'].isin( least_freq_hours_in_test_data ) ).astype('uint8')\n",
    "        log_feature(df,key,[])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_cols( df, group_cols, agg_name, agg_type='uint32', show_max=False, show_agg=True):\n",
    "    if show_agg:\n",
    "        print( \"Aggregating by \", group_cols , '...' )\n",
    "    gp = skip_if_already_exists(agg_name) \n",
    "    if gp is None:\n",
    "        gp = df[group_cols][group_cols].groupby(group_cols).size().rename(agg_name).to_frame().reset_index()\n",
    "        log_feature(gp,agg_name,group_cols)\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_FEATURES='base_features'\n",
    "def base_features(df,key=BASE_FEATURES):\n",
    "    gp=skip_if_already_exists(key)\n",
    "    if gp is None:\n",
    "        log_feature(df,key,group_cols=[])\n",
    "        return df\n",
    "    return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GROUP FEATURES\n",
    "IP_DAY_TEST_HH='IP_DAY_TEST_HH'\n",
    "IP_DAY_HH='IP_DAY_HH'\n",
    "IP_OS_HH='IP_OS_HH'\n",
    "IP_APP_HH='IP_APP_HH'\n",
    "IP_APP_OS_HH='IP_APP_OS_HH'\n",
    "APP_DAY_HH='APP_DAY_HH'\n",
    "def ip_day_test(df,key = IP_DAY_TEST_HH):\n",
    "    return aggregate_cols(df, ['ip', 'day', IN_TEST_HH], key, show_max=True )\n",
    "def ip_day_hh(df,key = IP_DAY_HH):\n",
    "    return aggregate_cols( df, ['ip', 'day', 'hour'], key, 'uint16', show_max=True );\n",
    "def ip_os_hh(df,key = IP_OS_HH):\n",
    "    return aggregate_cols( df, ['ip', 'day', 'os', 'hour'], key, 'uint16', show_max=True );\n",
    "def ip_app_hh(df,key = IP_APP_HH):\n",
    "    return aggregate_cols( df, ['ip', 'day', 'app', 'hour'], key, 'uint16', show_max=True );\n",
    "def ip_app_os_hh(df,key = IP_APP_OS_HH):\n",
    "    return aggregate_cols( df, ['ip', 'day', 'app', 'os', 'hour'], key, 'uint16', show_max=True );\n",
    "def app_day_hh(df,key = APP_DAY_HH):\n",
    "    return aggregate_cols( df, ['app', 'day', 'hour'], key, 'uint16', show_max=True );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_name(cols,prefix=''):\n",
    "    return prefix+'_'.join(cols).replace('is_attributed_','')[0:80]\n",
    "def cluster(df,n):\n",
    "    res=AgglomerativeClustering(n_clusters=n).fit(df)\n",
    "    import pandas as pd \n",
    "    df_clusters = pd.DataFrame(res.labels_)\n",
    "    df_clusters.to_csv(joint_name(df.columns),index=False)\n",
    "    return (df_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NON_FRAUD_PERC_IP='NON_FRAUD_PERC_IP'\n",
    "def get_non_fraud_perc_ip(df,col=['ip']):\n",
    "    if 'is_attributed' not in df.columns:\n",
    "        print('is attriuted not a part of columns, skipping this one')\n",
    "        return df\n",
    "    agg_name=joint_name(col,'perc_')\n",
    "    gp = skip_if_already_exists(agg_name) \n",
    "    if gp is None:\n",
    "        val=df.groupby(col)['is_attributed']\n",
    "        gp=(val.sum()/val.count()).rename(agg_name).to_frame().reset_index()\n",
    "        gp=gp.reset_index()\n",
    "        log_feature(gp,name=agg_name,group_cols=col)\n",
    "    df[agg_name] = gp[agg_name]\n",
    "    del gp\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_config={\n",
    "    BASE_FEATURES :base_features,\n",
    "    IN_TEST_HH    :in_test_hh,\n",
    "    IP_DAY_TEST_HH:ip_day_test,\n",
    "    IP_DAY_HH     :ip_day_hh,\n",
    "    IP_OS_HH      : ip_os_hh,\n",
    "    IP_APP_HH     :ip_app_hh,\n",
    "    IP_APP_OS_HH  :ip_app_os_hh,\n",
    "    APP_DAY_HH    :app_day_hh,\n",
    "    NON_FRAUD_PERC_IP:get_non_fraud_perc_ip\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "applicable_features=[\n",
    "    BASE_FEATURES,\n",
    "    NON_FRAUD_PERC_IP,\n",
    "    IN_TEST_HH,  \n",
    "    IP_DAY_TEST_HH,\n",
    "    IP_DAY_HH     ,\n",
    "    IP_OS_HH      ,\n",
    "    IP_APP_HH     ,\n",
    "    IP_APP_OS_HH  ,\n",
    "    APP_DAY_HH    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(file):\n",
    "    df=pd.read_csv(file)\n",
    "    set_file(file)\n",
    "    for each_feature in applicable_features:\n",
    "        print('generating '+each_feature+'...')\n",
    "        df=feature_config[each_feature](df)\n",
    "        print(feature_file(each_feature))\n",
    "    df.to_csv(feature_file('all_features'),index=False)\n",
    "    print(feature_file('all_features'))\n",
    "    del df\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating base_features...\n",
      "deleting  eda/features/valid/base_features_valid_hr_is_test_hr.csv ...\n",
      "eda/features/valid/base_features_valid_hr_is_test_hr.csv\n",
      "generating NON_FRAUD_PERC_IP...\n",
      "deleting  eda/features/valid/perc_ip_valid_hr_is_test_hr.csv ...\n",
      "eda/features/valid/non_fraud_perc_ip_valid_hr_is_test_hr.csv\n",
      "generating IN_TEST_HH...\n",
      "deleting  eda/features/valid/in_test_hh_valid_hr_is_test_hr.csv ...\n",
      "eda/features/valid/in_test_hh_valid_hr_is_test_hr.csv\n",
      "generating IP_DAY_TEST_HH...\n",
      "Aggregating by  ['ip', 'day', 'IN_TEST_HH'] ...\n",
      "deleting  eda/features/valid/ip_day_test_hh_valid_hr_is_test_hr.csv ...\n",
      "IP_DAY_TEST_HH max value =  917\n",
      "eda/features/valid/ip_day_test_hh_valid_hr_is_test_hr.csv\n",
      "generating IP_DAY_HH...\n",
      "Aggregating by  ['ip', 'day', 'hour'] ...\n",
      "deleting  eda/features/valid/ip_day_hh_valid_hr_is_test_hr.csv ...\n",
      "IP_DAY_HH max value =  237\n",
      "eda/features/valid/ip_day_hh_valid_hr_is_test_hr.csv\n",
      "generating IP_OS_HH...\n",
      "Aggregating by  ['ip', 'day', 'os', 'hour'] ...\n",
      "deleting  eda/features/valid/ip_os_hh_valid_hr_is_test_hr.csv ...\n",
      "IP_OS_HH max value =  55\n",
      "eda/features/valid/ip_os_hh_valid_hr_is_test_hr.csv\n",
      "generating IP_APP_HH...\n",
      "Aggregating by  ['ip', 'day', 'app', 'hour'] ...\n",
      "deleting  eda/features/valid/ip_app_hh_valid_hr_is_test_hr.csv ...\n",
      "IP_APP_HH max value =  41\n",
      "eda/features/valid/ip_app_hh_valid_hr_is_test_hr.csv\n",
      "generating IP_APP_OS_HH...\n",
      "Aggregating by  ['ip', 'day', 'app', 'os', 'hour'] ...\n",
      "deleting  eda/features/valid/ip_app_os_hh_valid_hr_is_test_hr.csv ...\n",
      "IP_APP_OS_HH max value =  11\n",
      "eda/features/valid/ip_app_os_hh_valid_hr_is_test_hr.csv\n",
      "generating APP_DAY_HH...\n",
      "Aggregating by  ['app', 'day', 'hour'] ...\n",
      "deleting  eda/features/valid/app_day_hh_valid_hr_is_test_hr.csv ...\n",
      "APP_DAY_HH max value =  4750\n",
      "eda/features/valid/app_day_hh_valid_hr_is_test_hr.csv\n",
      "eda/features/valid/all_features_valid_hr_is_test_hr.csv\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    0.0\n",
       "Name: perc_ip, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_features(valid_file)\n",
    "dd=pd.read_csv('eda/features/valid/all_features_valid_hr_is_test_hr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating base_features...\n",
      "deleting  eda/features/train/base_features_valid_hr_is_test_hr.csv ...\n",
      "eda/features/train/base_features_valid_hr_is_test_hr.csv\n",
      "generating NON_FRAUD_PERC_IP...\n",
      "deleting  eda/features/train/perc_ip_valid_hr_is_test_hr.csv ...\n",
      "eda/features/train/non_fraud_perc_ip_valid_hr_is_test_hr.csv\n",
      "generating IN_TEST_HH...\n",
      "deleting  eda/features/train/in_test_hh_valid_hr_is_test_hr.csv ...\n",
      "eda/features/train/in_test_hh_valid_hr_is_test_hr.csv\n",
      "generating IP_DAY_TEST_HH...\n",
      "Aggregating by  ['ip', 'day', 'IN_TEST_HH'] ...\n",
      "deleting  eda/features/train/ip_day_test_hh_valid_hr_is_test_hr.csv ...\n",
      "IP_DAY_TEST_HH max value =  1117\n",
      "eda/features/train/ip_day_test_hh_valid_hr_is_test_hr.csv\n",
      "generating IP_DAY_HH...\n",
      "Aggregating by  ['ip', 'day', 'hour'] ...\n",
      "deleting  eda/features/train/ip_day_hh_valid_hr_is_test_hr.csv ...\n",
      "IP_DAY_HH max value =  247\n",
      "eda/features/train/ip_day_hh_valid_hr_is_test_hr.csv\n",
      "generating IP_OS_HH...\n",
      "Aggregating by  ['ip', 'day', 'os', 'hour'] ...\n",
      "deleting  eda/features/train/ip_os_hh_valid_hr_is_test_hr.csv ...\n",
      "IP_OS_HH max value =  59\n",
      "eda/features/train/ip_os_hh_valid_hr_is_test_hr.csv\n",
      "generating IP_APP_HH...\n",
      "Aggregating by  ['ip', 'day', 'app', 'hour'] ...\n",
      "deleting  eda/features/train/ip_app_hh_valid_hr_is_test_hr.csv ...\n",
      "IP_APP_HH max value =  45\n",
      "eda/features/train/ip_app_hh_valid_hr_is_test_hr.csv\n",
      "generating IP_APP_OS_HH...\n",
      "Aggregating by  ['ip', 'day', 'app', 'os', 'hour'] ...\n",
      "deleting  eda/features/train/ip_app_os_hh_valid_hr_is_test_hr.csv ...\n",
      "IP_APP_OS_HH max value =  15\n",
      "eda/features/train/ip_app_os_hh_valid_hr_is_test_hr.csv\n",
      "generating APP_DAY_HH...\n",
      "Aggregating by  ['app', 'day', 'hour'] ...\n",
      "deleting  eda/features/train/app_day_hh_valid_hr_is_test_hr.csv ...\n",
      "APP_DAY_HH max value =  4433\n",
      "eda/features/train/app_day_hh_valid_hr_is_test_hr.csv\n",
      "eda/features/train/all_features_valid_hr_is_test_hr.csv\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "      <th>attributed_time</th>\n",
       "      <th>is_attributed</th>\n",
       "      <th>click_date</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>minute</th>\n",
       "      <th>perc_ip</th>\n",
       "      <th>IN_TEST_HH</th>\n",
       "      <th>IP_DAY_TEST_HH</th>\n",
       "      <th>IP_DAY_HH</th>\n",
       "      <th>IP_OS_HH</th>\n",
       "      <th>IP_APP_HH</th>\n",
       "      <th>IP_APP_OS_HH</th>\n",
       "      <th>APP_DAY_HH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46371</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>481</td>\n",
       "      <td>2017-11-08 04:15:09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-08 00:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46680</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>325</td>\n",
       "      <td>2017-11-08 11:05:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-08 00:00:00</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28564</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>107</td>\n",
       "      <td>2017-11-06 17:35:13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-06 00:00:00</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44527</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>459</td>\n",
       "      <td>2017-11-08 13:01:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-08 00:00:00</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12505</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>452</td>\n",
       "      <td>2017-11-08 06:18:29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-08 00:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ip  app  device  os  channel           click_time attributed_time  \\\n",
       "0  46371   12       1  14      481  2017-11-08 04:15:09             NaN   \n",
       "1  46680   11       1  19      325  2017-11-08 11:05:23             NaN   \n",
       "2  28564   18       1  13      107  2017-11-06 17:35:13             NaN   \n",
       "3  44527    6       1  15      459  2017-11-08 13:01:18             NaN   \n",
       "4  12505    2       1  25      452  2017-11-08 06:18:29             NaN   \n",
       "\n",
       "   is_attributed           click_date  hour  day  minute  perc_ip  IN_TEST_HH  \\\n",
       "0              0  2017-11-08 00:00:00     4    8      15      0.0           1   \n",
       "1              0  2017-11-08 00:00:00    11    8       5      0.0           2   \n",
       "2              0  2017-11-06 00:00:00    17    6      35      0.0           3   \n",
       "3              0  2017-11-08 00:00:00    13    8       1      0.0           1   \n",
       "4              0  2017-11-08 00:00:00     6    8      18      0.0           2   \n",
       "\n",
       "   IP_DAY_TEST_HH  IP_DAY_HH  IP_OS_HH  IP_APP_HH  IP_APP_OS_HH  APP_DAY_HH  \n",
       "0               3          1         1          1             1        2524  \n",
       "1               6          3         1          1             1         388  \n",
       "2               3          1         1          1             1         662  \n",
       "3              29          7         1          1             1         275  \n",
       "4              11          2         1          2             1        2365  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_features(train_file)\n",
    "pd.read_csv('eda/features/train/all_features_valid_hr_is_test_hr.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating base_features...\n",
      "deleting  eda/features/test/base_features.csv ...\n",
      "eda/features/test/base_features.csv\n",
      "generating IN_TEST_HH...\n",
      "eda/features/test/in_test_hh.csv\n",
      "generating IP_DAY_TEST_HH...\n",
      "Aggregating by  ['ip', 'day', 'IN_TEST_HH'] ...\n",
      "IP_DAY_TEST_HH max value =  182513\n",
      "eda/features/test/ip_day_test_hh.csv\n",
      "generating IP_DAY_HH...\n",
      "Aggregating by  ['ip', 'day', 'hour'] ...\n",
      "IP_DAY_HH max value =  40231\n",
      "eda/features/test/ip_day_hh.csv\n",
      "generating IP_OS_HH...\n",
      "Aggregating by  ['ip', 'day', 'os', 'hour'] ...\n",
      "IP_OS_HH max value =  8224\n",
      "eda/features/test/ip_os_hh.csv\n",
      "generating IP_APP_HH...\n",
      "Aggregating by  ['ip', 'day', 'app', 'hour'] ...\n",
      "IP_APP_HH max value =  6250\n",
      "eda/features/test/ip_app_hh.csv\n",
      "generating IP_APP_OS_HH...\n",
      "Aggregating by  ['ip', 'day', 'app', 'os', 'hour'] ...\n",
      "IP_APP_OS_HH max value =  1307\n",
      "eda/features/test/ip_app_os_hh.csv\n",
      "generating APP_DAY_HH...\n",
      "Aggregating by  ['app', 'day', 'hour'] ...\n",
      "APP_DAY_HH max value =  522993\n",
      "eda/features/test/app_day_hh.csv\n",
      "eda/features/test/all_features.csv\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "test_file='input/test_parsed.csv'\n",
    "get_features(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST TO check whetther correct data is written\n",
    "# df1=df\n",
    "# feat_1=[IN_TEST_HH]\n",
    "# for feat in feat_1:\n",
    "#     df1=feature_config[feat](df1)\n",
    "# assert('IN_TEST_HH' in df1.columns)\n",
    "\n",
    "# print('2nd')\n",
    "# feat_2=[NON_FRAUD_PERC_IP,IN_TEST_HH]\n",
    "# for feat in feat_1:\n",
    "#     df1=feature_config[feat](df1)\n",
    "# assert('perc_ip' in df1.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
